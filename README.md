import sqlglot
import openai
import json


class SQLQueryEvaluator:
    def __init__(self, model_name="gpt-5", temperature=0):
        """
        Initialize the SQL Query Evaluator.
        :param model_name: Azure OpenAI / GPT model name.
        :param temperature: LLM randomness; keep 0 for deterministic outputs.
        """
        self.model_name = model_name
        self.temperature = temperature
        self.prompt_template = """
        You are an expert Azure Databricks SQL evaluator.

        You will compare two SQL queries:
        1. The actual correct query.
        2. The predicted query generated by a model.

        Your task:
        - Check SELECT columns, WHERE filters, JOINs, GROUP BY, ORDER BY, and LIMIT.
        - Find missing parts, extra parts, and incorrect logic.
        - Give a score from 0-100 based on logical similarity.
        - Suggest the corrected SQL query.

        Output ONLY in this JSON format:
        {
          "score": "<integer>",
          "missing_parts": ["<list of missing filters/columns/joins>"],
          "extra_parts": ["<list of unnecessary filters/columns/joins>"],
          "incorrect_parts": ["<list of wrong aggregations/joins>"],
          "explanation": "<short explanation>",
          "suggested_fix": "<fixed SQL query>"
        }
        """

    def validate_sql(self, query: str) -> bool:
        """
        Validate the syntax of a SQL query using sqlglot.
        :param query: SQL query string.
        :return: True if valid, False otherwise.
        """
        try:
            sqlglot.parse_one(query, read="spark")
            return True
        except Exception:
            return False

    def evaluate(self, actual_query: str, predicted_query: str) -> dict:
        """
        Evaluate predicted SQL query against actual query.
        :param actual_query: Correct Databricks SQL query.
        :param predicted_query: LLM-generated SQL query.
        :return: JSON report with score, missing parts, extra parts, explanation, and suggested fix.
        """
        # Step 1: Syntax check
        if not self.validate_sql(predicted_query):
            return {
                "score": 0,
                "missing_parts": [],
                "extra_parts": [],
                "incorrect_parts": [],
                "explanation": "Predicted query has invalid syntax.",
                "suggested_fix": actual_query
            }

        # Step 2: Prepare LLM input
        user_input = f"""
        ACTUAL QUERY:
        {actual_query}

        PREDICTED QUERY:
        {predicted_query}
        """

        # Step 3: Call Azure OpenAI (GPT-5)
        try:
            response = openai.ChatCompletion.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": self.prompt_template},
                    {"role": "user", "content": user_input}
                ],
                temperature=self.temperature
            )
            llm_output = response['choices'][0]['message']['content']
        except Exception as e:
            return {
                "score": 0,
                "missing_parts": [],
                "extra_parts": [],
                "incorrect_parts": [],
                "explanation": f"LLM API call failed: {str(e)}",
                "suggested_fix": actual_query
            }

        # Step 4: Parse LLM JSON output
        try:
            result = json.loads(llm_output)
        except:
            result = {
                "score": 0,
                "missing_parts": [],
                "extra_parts": [],
                "incorrect_parts": [],
                "explanation": "Failed to parse LLM output.",
                "suggested_fix": actual_query
            }

        return result

